{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea8pR9S88WVW"
   },
   "source": [
    "## NLP TWITTER ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIYxZnfk8WVz"
   },
   "source": [
    "* Final Project Submission\n",
    "* Group Members\n",
    "   1. Benson Kamau\n",
    "   2. Kevin Muchori\n",
    "   3. Nancy Chelangat\n",
    "   4. Sally Kinyanjui\n",
    "   5. Breden Mugambi\n",
    "\n",
    "* Student Pace: Full-Time\n",
    "* Instructor's: Nikita Njoroge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdWwsNjs8WV0"
   },
   "source": [
    "### Problem Statement\n",
    "Accurately classifying the sentiments expressed in tweets about topics or brands into specific classes- positive, negative or neutral is a huge challenge for companies like Apple and Google. Given the diverse nature of informal data, with its use of slang, abbreviations, coming up with a reliable sentiment analysis model that can effectively interpret and classify the tweets can be a complex task. Getting this task right provides a wide variety of novel information for a company like Apple by providing insights and creating better understanding overall of how consumers interact with products/brands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6lWgPtP8WV1"
   },
   "source": [
    "### Objective\n",
    "The main objective is to build a model that can rate the sentiment of  a tweet based on its content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z08gzkdG8WV7"
   },
   "source": [
    "#### Project Success Metrics\n",
    "Over 75% accuracy on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdltzbpU8WWK"
   },
   "source": [
    "#### Importing relavent Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Rgz5FRV8WWL",
    "outputId": "e7f4764a-a3cb-478f-b775-7745ed300c9e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize,TweetTokenizer, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xW-Z056e8WWY"
   },
   "source": [
    "### 1. Data Loading and Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cx0A2w7e8WWZ"
   },
   "source": [
    "The dataset that will be used in this study comes from CrowdFlower via data.world through this link - https://data.world/crowdflower/brands-and-product-emotions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x9MZfQTS8WWa"
   },
   "outputs": [],
   "source": [
    "#create a function that loads data and gets the info about the data.\n",
    "def load_and_get_info(file_path, encoding='utf-8'):\n",
    "    try :\n",
    "        # Load data\n",
    "        df = pd.read_csv(file_path, encoding=encoding)\n",
    "\n",
    "        # Display the first few rows of the DataFrame\n",
    "        df_head = df.head()\n",
    "\n",
    "        # Get information about the DataFrame\n",
    "        df_info = df.info()\n",
    "\n",
    "        return df,df_info, df_head\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed to decode {file_path} with encoding {encoding}. Trying with 'latin1' encoding.\")\n",
    "        return load_and_get_info(file_path, encoding='latin1')\n",
    "\n",
    "# A function that checks the data types of DataFrame columns and return the count of columns for each data type category.\n",
    "def check_data_types(df):\n",
    "\n",
    "    data_type_counts = df.dtypes.replace({'object': 'string'}).value_counts().to_dict()\n",
    "    return data_type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "xesI4pnF8WWc",
    "outputId": "d30d547a-01c8-40a8-b099-410a5fbbf4ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode tweet-analysis.csv with encoding utf-8. Trying with 'latin1' encoding.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n",
      "None\n",
      "\n",
      "First few rows of the DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path1 = 'tweet-analysis.csv'\n",
    "df1,data_info, data_head = load_and_get_info(file_path1)\n",
    "print(data_info)\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "data_head #data_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrXQCBEb8WWt"
   },
   "source": [
    "The dataset contains the following columns:\n",
    "\n",
    "1. 'tweet_text' column\n",
    "    - Contains the text of the tweet.\n",
    "2. 'emotion_in_tweet_is_directed_at' column\n",
    "    - Contains the person or entity that the tweet is directed at.\n",
    "3. 'is_there_an_emotion_directed_at_a_brand_or_product' column\n",
    "    - Indicates the kind of emotion in the tweet directed at the brand or product\n",
    "\n",
    "The dataset has a total of 9093 data points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydnggXcA8WWw",
    "outputId": "c5766490-7e2d-4517-9922-925e9fc6859d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of columns for each data type category:\n",
      "{'string': 3}\n"
     ]
    }
   ],
   "source": [
    "#check the data types of DataFrame columns in our training set values.\n",
    "data_type_counts = check_data_types(df1)\n",
    "print(\"Count of columns for each data type category:\")\n",
    "print(data_type_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AYcqwwZ8WWx"
   },
   "source": [
    "The dataset has one data type category .i., object type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPi_ltSz8WWx"
   },
   "source": [
    "To simplify working with the dataset, we will rename the columns to simpler and shorter names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "-GokMzMp8WWy",
    "outputId": "19f266e5-39ea-43fc-e2d4-1ab9e81a99a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Renamed DataFrame columns:\n",
      "Index(['tweet', 'target_entity', 'emotion'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target_entity</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet       target_entity  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            emotion  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to rename the column names\n",
    "def rename_columns(df, columns_dict):\n",
    "    \"\"\"\n",
    "   Parameters:\n",
    "    df (pd.DataFrame): The DataFrame whose columns need to be renamed.\n",
    "    columns_dict (dict): A dictionary where keys are current column names and values are the new column names.\n",
    "    \"\"\"\n",
    "    df.rename(columns=columns_dict, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Define the dictionary for renaming columns\n",
    "columns_dict = {\n",
    "    'tweet_text': 'tweet',\n",
    "    'emotion_in_tweet_is_directed_at': 'target_entity',\n",
    "    'is_there_an_emotion_directed_at_a_brand_or_product': 'emotion'\n",
    "}\n",
    "\n",
    "# Rename columns using the dictionary\n",
    "df1 = rename_columns(df1, columns_dict)\n",
    "\n",
    "print(\"\\nRenamed DataFrame columns:\")\n",
    "print(df1.columns)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-4s8oqk8WWy"
   },
   "source": [
    "The dataset has been successfully renamed and the column names are now more descriptive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylIiF6vg8ljY"
   },
   "source": [
    "# Data Cleaning\n",
    "This is an essential aspect so as to ensure that the text data is consistent and free of errors. For this project, we will check for missing values, checking for duplicates,\n",
    "remove white spaces, handle capitalization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmT2o4DJ_NF6",
    "outputId": "262863d7-eb38-4848-b2dc-e4ea8a78814d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet               1\n",
       "target_entity    5802\n",
       "emotion             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZjfpFXP_Ggn"
   },
   "source": [
    "There is only one missing tweet text value, which will be removed. There are 5,802 missing \"target_entity\" values; however, this is acceptable since the current project focuses on overall tweet sentiment rather than specific items. These missing values will be replaced with an \"Uncategorized\" classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TGSQpoJsBOsS",
    "outputId": "f3a4c3b6-7995-4ae2-a27f-38621d961687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9070 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   tweet          9070 non-null   object\n",
      " 1   target_entity  9070 non-null   object\n",
      " 2   emotion        9070 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 283.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#Removing Null Tweets, Removing Duplicate entries and Filling in missing Item Values\n",
    "\n",
    "#Removing 1 null 'Tweet' Entry\n",
    "df1.dropna(subset = ['tweet'], inplace=True)\n",
    "\n",
    "#Removing Duplicates\n",
    "df1.drop_duplicates(inplace=True)\n",
    "\n",
    "#Filling in Null \"Item\" categories with \"Uncategorized\"\n",
    "df1['target_entity'].fillna('Uncategorized', inplace=True)\n",
    "\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZ-LrgnzBzmo"
   },
   "source": [
    "At this point there should not be any duplicate entries or null values in the data and the total row count in the dataset has decreased from 9092 to 9070."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLhtBtcbACx1"
   },
   "source": [
    "Text Cleaning: The function below cleans the tweet column by removing white spaces, converting to lower case, and removing special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "KOolkN-Y8WWy",
    "outputId": "9266ee57-09be-4f09-99a0-a9fe055ce2ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target_entity</th>\n",
       "      <th>emotion</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley83 i have a 3g iphone after 3 hrs tweeti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee know about fludapp  awesome ipadiphon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin can not wait for ipad 2 also they s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>sxsw i hope this years festival isnt as crashy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff on fri sxsw marissa maye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet       target_entity  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            emotion                                      cleaned_tweet  \n",
       "0  Negative emotion  wesley83 i have a 3g iphone after 3 hrs tweeti...  \n",
       "1  Positive emotion  jessedee know about fludapp  awesome ipadiphon...  \n",
       "2  Positive emotion  swonderlin can not wait for ipad 2 also they s...  \n",
       "3  Negative emotion  sxsw i hope this years festival isnt as crashy...  \n",
       "4  Positive emotion  sxtxstate great stuff on fri sxsw marissa maye...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    pattern = re.compile(r'[^a-zA-Z0-9\\s]')\n",
    "    text = pattern.sub('', text)\n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function to the tweet column\n",
    "df1['cleaned_tweet'] = df1['tweet'].apply(clean_text)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zx48LjRrLUA_"
   },
   "source": [
    "The additional column cleaned_tweet stores the text after text cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization ,stop word removal and tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a combined process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization of tweet_text\n",
    "lemmatized = []\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "for lists in df1:\n",
    "    lemmed = ' '.join([lemmatizer.lemmatize(w) for w in lists])\n",
    "    lemmatized.append(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t w e e t',\n",
       " 't a r g e t _ e n t i t y',\n",
       " 'e m o t i o n',\n",
       " 'c l e a n e d _ t w e e t']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#lemmatized output\n",
    "lemmatized[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-1-aba653132ce3>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-aba653132ce3>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    return r_stop_words\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text_nltk(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    r_stop_words = [word for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    "  return r_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize and remove stopwords and punctuation\n",
    "def process_tweet(tweet):\n",
    "    tweet = tweet.lower() #convert tweet to lowercase\n",
    "    # Define a regular expression pattern to match words including apostrophes\n",
    "    pattern = r\"\\b\\w+(?:'\\w+)?\\b\"\n",
    "    # Create a RegexpTokenizer with the defined pattern\n",
    "    tokenizer = RegexpTokenizer(pattern)\n",
    "    # Tokenize tweet\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english') \n",
    "              and token not in punctuation]                                    #remove stopwords and punctuations\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
