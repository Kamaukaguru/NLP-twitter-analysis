{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea8pR9S88WVW"
   },
   "source": [
    "## NLP TWITTER ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIYxZnfk8WVz"
   },
   "source": [
    "* Final Project Submission\n",
    "* Group Members\n",
    "   1. Benson Kamau\n",
    "   2. Kevin Muchori\n",
    "   3. Nancy Chelangat\n",
    "   4. Sally Kinyanjui\n",
    "   5. Breden Mugambi\n",
    "\n",
    "* Student Pace: Full-Time\n",
    "* Instructor's: Nikita Njoroge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdWwsNjs8WV0"
   },
   "source": [
    "### Problem Statement\n",
    "Accurately classifying the sentiments expressed in tweets about topics or brands into specific classes- positive, negative or neutral is a huge challenge for companies like Apple and Google. Given the diverse nature of informal data, with its use of slang, abbreviations, coming up with a reliable sentiment analysis model that can effectively interpret and classify the tweets can be a complex task. Getting this task right provides a wide variety of novel information for a company like Apple by providing insights and creating better understanding overall of how consumers interact with products/brands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6lWgPtP8WV1"
   },
   "source": [
    "### Objective\n",
    "The main objective is to build a model that can rate the sentiment of  a tweet based on its content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z08gzkdG8WV7"
   },
   "source": [
    "#### Project Success Metrics\n",
    "Over 75% accuracy on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdltzbpU8WWK"
   },
   "source": [
    "#### Importing relavent Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Rgz5FRV8WWL",
    "outputId": "e7f4764a-a3cb-478f-b775-7745ed300c9e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize,TweetTokenizer, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xW-Z056e8WWY"
   },
   "source": [
    "### 1. Data Loading and Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cx0A2w7e8WWZ"
   },
   "source": [
    "The dataset that will be used in this study comes from CrowdFlower via data.world through this link - https://data.world/crowdflower/brands-and-product-emotions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x9MZfQTS8WWa"
   },
   "outputs": [],
   "source": [
    "#create a function that loads data and gets the info about the data.\n",
    "def load_and_get_info(file_path, encoding='utf-8'):\n",
    "    try :\n",
    "        # Load data\n",
    "        df = pd.read_csv(file_path, encoding=encoding)\n",
    "\n",
    "        # Display the first few rows of the DataFrame\n",
    "        df_head = df.head()\n",
    "\n",
    "        # Get information about the DataFrame\n",
    "        df_info = df.info()\n",
    "\n",
    "        return df,df_info, df_head\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed to decode {file_path} with encoding {encoding}. Trying with 'latin1' encoding.\")\n",
    "        return load_and_get_info(file_path, encoding='latin1')\n",
    "\n",
    "# A function that checks the data types of DataFrame columns and return the count of columns for each data type category.\n",
    "def check_data_types(df):\n",
    "\n",
    "    data_type_counts = df.dtypes.replace({'object': 'string'}).value_counts().to_dict()\n",
    "    return data_type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "xesI4pnF8WWc",
    "outputId": "d30d547a-01c8-40a8-b099-410a5fbbf4ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode tweet-analysis.csv with encoding utf-8. Trying with 'latin1' encoding.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n",
      "None\n",
      "\n",
      "First few rows of the DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path1 = 'tweet-analysis.csv'\n",
    "df1,data_info, data_head = load_and_get_info(file_path1)\n",
    "print(data_info)\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "data_head #data_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrXQCBEb8WWt"
   },
   "source": [
    "The dataset contains the following columns:\n",
    "\n",
    "1. 'tweet_text' column\n",
    "    - Contains the text of the tweet.\n",
    "2. 'emotion_in_tweet_is_directed_at' column\n",
    "    - Contains the person or entity that the tweet is directed at.\n",
    "3. 'is_there_an_emotion_directed_at_a_brand_or_product' column\n",
    "    - Indicates the kind of emotion in the tweet directed at the brand or product\n",
    "\n",
    "The dataset has a total of 9093 data points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydnggXcA8WWw",
    "outputId": "c5766490-7e2d-4517-9922-925e9fc6859d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of columns for each data type category:\n",
      "{'string': 3}\n"
     ]
    }
   ],
   "source": [
    "#check the data types of DataFrame columns in our training set values.\n",
    "data_type_counts = check_data_types(df1)\n",
    "print(\"Count of columns for each data type category:\")\n",
    "print(data_type_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AYcqwwZ8WWx"
   },
   "source": [
    "The dataset has one data type category .i., object type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPi_ltSz8WWx"
   },
   "source": [
    "To simplify working with the dataset, we will rename the columns to simpler and shorter names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "-GokMzMp8WWy",
    "outputId": "19f266e5-39ea-43fc-e2d4-1ab9e81a99a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Renamed DataFrame columns:\n",
      "Index(['tweet', 'target_entity', 'emotion'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target_entity</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet       target_entity  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            emotion  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to rename the column names\n",
    "def rename_columns(df, columns_dict):\n",
    "    \"\"\"\n",
    "   Parameters:\n",
    "    df (pd.DataFrame): The DataFrame whose columns need to be renamed.\n",
    "    columns_dict (dict): A dictionary where keys are current column names and values are the new column names.\n",
    "    \"\"\"\n",
    "    df.rename(columns=columns_dict, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Define the dictionary for renaming columns\n",
    "columns_dict = {\n",
    "    'tweet_text': 'tweet',\n",
    "    'emotion_in_tweet_is_directed_at': 'target_entity',\n",
    "    'is_there_an_emotion_directed_at_a_brand_or_product': 'emotion'\n",
    "}\n",
    "\n",
    "# Rename columns using the dictionary\n",
    "df1 = rename_columns(df1, columns_dict)\n",
    "\n",
    "print(\"\\nRenamed DataFrame columns:\")\n",
    "print(df1.columns)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-4s8oqk8WWy"
   },
   "source": [
    "The dataset has been successfully renamed and the column names are now more descriptive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylIiF6vg8ljY"
   },
   "source": [
    "# Data Cleaning\n",
    "This is an essential aspect so as to ensure that the text data is consistent and free of errors. For this project, we will check for missing values, checking for duplicates,\n",
    "remove white spaces, handle capitalization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmT2o4DJ_NF6",
    "outputId": "262863d7-eb38-4848-b2dc-e4ea8a78814d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet               1\n",
       "target_entity    5802\n",
       "emotion             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZjfpFXP_Ggn"
   },
   "source": [
    "There is only one missing tweet text value, which will be removed. There are 5,802 missing \"target_entity\" values; however, this is acceptable since the current project focuses on overall tweet sentiment rather than specific items. These missing values will be replaced with an \"Uncategorized\" classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TGSQpoJsBOsS",
    "outputId": "f3a4c3b6-7995-4ae2-a27f-38621d961687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9070 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   tweet          9070 non-null   object\n",
      " 1   target_entity  9070 non-null   object\n",
      " 2   emotion        9070 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 283.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#Removing Null Tweets, Removing Duplicate entries and Filling in missing Item Values\n",
    "\n",
    "#Removing 1 null 'Tweet' Entry\n",
    "df1.dropna(subset = ['tweet'], inplace=True)\n",
    "\n",
    "#Removing Duplicates\n",
    "df1.drop_duplicates(inplace=True)\n",
    "\n",
    "#Filling in Null \"Item\" categories with \"Uncategorized\"\n",
    "df1['target_entity'].fillna('Uncategorized', inplace=True)\n",
    "\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZ-LrgnzBzmo"
   },
   "source": [
    "At this point there should not be any duplicate entries or null values in the data and the total row count in the dataset has decreased from 9092 to 9070."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLhtBtcbACx1"
   },
   "source": [
    "Text Cleaning: The function below cleans the tweet column by removing white spaces, converting to lower case, and removing special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "KOolkN-Y8WWy",
    "outputId": "9266ee57-09be-4f09-99a0-a9fe055ce2ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target_entity</th>\n",
       "      <th>emotion</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley83 i have a 3g iphone after 3 hrs tweeti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee know about fludapp  awesome ipadiphon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin can not wait for ipad 2 also they s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>sxsw i hope this years festival isnt as crashy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff on fri sxsw marissa maye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet       target_entity  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            emotion                                      cleaned_tweet  \n",
       "0  Negative emotion  wesley83 i have a 3g iphone after 3 hrs tweeti...  \n",
       "1  Positive emotion  jessedee know about fludapp  awesome ipadiphon...  \n",
       "2  Positive emotion  swonderlin can not wait for ipad 2 also they s...  \n",
       "3  Negative emotion  sxsw i hope this years festival isnt as crashy...  \n",
       "4  Positive emotion  sxtxstate great stuff on fri sxsw marissa maye...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    pattern = re.compile(r'[^a-zA-Z0-9\\s]')\n",
    "    text = pattern.sub('', text)\n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function to the tweet column\n",
    "df1['cleaned_tweet'] = df1['tweet'].apply(clean_text)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zx48LjRrLUA_"
   },
   "source": [
    "The additional column cleaned_tweet stores the text after text cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization ,stop word removal and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target_entity</th>\n",
       "      <th>emotion</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>lemmatized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley83 i have a 3g iphone after 3 hrs tweeti...</td>\n",
       "      <td>wesley83 i have a 3g iphone after 3 hr tweetin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee know about fludapp  awesome ipadiphon...</td>\n",
       "      <td>jessedee know about fludapp awesome ipadiphone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin can not wait for ipad 2 also they s...</td>\n",
       "      <td>swonderlin can not wait for ipad 2 also they s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>sxsw i hope this years festival isnt as crashy...</td>\n",
       "      <td>sxsw i hope this year festival isnt a crashy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff on fri sxsw marissa maye...</td>\n",
       "      <td>sxtxstate great stuff on fri sxsw marissa maye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>teachntech00 new ipad apps for speechtherapy a...</td>\n",
       "      <td>teachntech00 new ipad apps for speechtherapy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxsw is just starting ctia is around the corne...</td>\n",
       "      <td>sxsw is just starting ctia is around the corne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beautifully smart and simple idea RT @madebyma...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>beautifully smart and simple idea rt madebyman...</td>\n",
       "      <td>beautifully smart and simple idea rt madebyman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Counting down the days to #sxsw plus strong Ca...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>counting down the days to sxsw plus strong can...</td>\n",
       "      <td>counting down the day to sxsw plus strong cana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Excited to meet the @samsungmobileus at #sxsw ...</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>excited to meet the samsungmobileus at sxsw so...</td>\n",
       "      <td>excited to meet the samsungmobileus at sxsw so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet       target_entity  \\\n",
       "0   .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1   @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2   @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3   @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4   @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "5   @teachntech00 New iPad Apps For #SpeechTherapy...       Uncategorized   \n",
       "7   #SXSW is just starting, #CTIA is around the co...             Android   \n",
       "8   Beautifully smart and simple idea RT @madebyma...  iPad or iPhone App   \n",
       "9   Counting down the days to #sxsw plus strong Ca...               Apple   \n",
       "10  Excited to meet the @samsungmobileus at #sxsw ...             Android   \n",
       "\n",
       "                               emotion  \\\n",
       "0                     Negative emotion   \n",
       "1                     Positive emotion   \n",
       "2                     Positive emotion   \n",
       "3                     Negative emotion   \n",
       "4                     Positive emotion   \n",
       "5   No emotion toward brand or product   \n",
       "7                     Positive emotion   \n",
       "8                     Positive emotion   \n",
       "9                     Positive emotion   \n",
       "10                    Positive emotion   \n",
       "\n",
       "                                        cleaned_tweet  \\\n",
       "0   wesley83 i have a 3g iphone after 3 hrs tweeti...   \n",
       "1   jessedee know about fludapp  awesome ipadiphon...   \n",
       "2   swonderlin can not wait for ipad 2 also they s...   \n",
       "3   sxsw i hope this years festival isnt as crashy...   \n",
       "4   sxtxstate great stuff on fri sxsw marissa maye...   \n",
       "5   teachntech00 new ipad apps for speechtherapy a...   \n",
       "7   sxsw is just starting ctia is around the corne...   \n",
       "8   beautifully smart and simple idea rt madebyman...   \n",
       "9   counting down the days to sxsw plus strong can...   \n",
       "10  excited to meet the samsungmobileus at sxsw so...   \n",
       "\n",
       "                                     lemmatized_tweet  \n",
       "0   wesley83 i have a 3g iphone after 3 hr tweetin...  \n",
       "1   jessedee know about fludapp awesome ipadiphone...  \n",
       "2   swonderlin can not wait for ipad 2 also they s...  \n",
       "3   sxsw i hope this year festival isnt a crashy a...  \n",
       "4   sxtxstate great stuff on fri sxsw marissa maye...  \n",
       "5   teachntech00 new ipad apps for speechtherapy a...  \n",
       "7   sxsw is just starting ctia is around the corne...  \n",
       "8   beautifully smart and simple idea rt madebyman...  \n",
       "9   counting down the day to sxsw plus strong cana...  \n",
       "10  excited to meet the samsungmobileus at sxsw so...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to lemmatize text\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Apply the lemmatize_text function to the 'cleaned_tweet' column\n",
    "df1['lemmatized_tweet'] = df1['cleaned_tweet'].apply(lemmatize_text)\n",
    "\n",
    "df1.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNetLemmatizer() is used to reduce words to their base or root form. This is what is known as lemmatization.\n",
    "\n",
    "This function def lemmatize_text(text)  tokenizes the input text into words,lemmatizes each word and joins the lemmatized words back into a string.\n",
    "\n",
    "From the output , the original tweet is the raw tweet text,the cleaned  tweet is the twwet after preprocessing  and the lemmatized tweet is the cleaned twwet after lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the input, english indicates that the output required is supposed to be a setg of English stop words.\n",
    "\n",
    "This set of stop words can be used in text preprocessing tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target_entity</th>\n",
       "      <th>emotion</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>lemmatized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley83 i have a 3g iphone after 3 hrs tweeti...</td>\n",
       "      <td>wesley83 i have a 3g iphone after 3 hr tweetin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee know about fludapp  awesome ipadiphon...</td>\n",
       "      <td>jessedee know about fludapp awesome ipadiphone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin can not wait for ipad 2 also they s...</td>\n",
       "      <td>swonderlin can not wait for ipad 2 also they s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>sxsw i hope this years festival isnt as crashy...</td>\n",
       "      <td>sxsw i hope this year festival isnt a crashy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff on fri sxsw marissa maye...</td>\n",
       "      <td>sxtxstate great stuff on fri sxsw marissa maye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>teachntech00 new ipad apps for speechtherapy a...</td>\n",
       "      <td>teachntech00 new ipad apps for speechtherapy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxsw is just starting ctia is around the corne...</td>\n",
       "      <td>sxsw is just starting ctia is around the corne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beautifully smart and simple idea RT @madebyma...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>beautifully smart and simple idea rt madebyman...</td>\n",
       "      <td>beautifully smart and simple idea rt madebyman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Counting down the days to #sxsw plus strong Ca...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>counting down the days to sxsw plus strong can...</td>\n",
       "      <td>counting down the day to sxsw plus strong cana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Excited to meet the @samsungmobileus at #sxsw ...</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>excited to meet the samsungmobileus at sxsw so...</td>\n",
       "      <td>excited to meet the samsungmobileus at sxsw so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet       target_entity  \\\n",
       "0   .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1   @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2   @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3   @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4   @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "5   @teachntech00 New iPad Apps For #SpeechTherapy...       Uncategorized   \n",
       "7   #SXSW is just starting, #CTIA is around the co...             Android   \n",
       "8   Beautifully smart and simple idea RT @madebyma...  iPad or iPhone App   \n",
       "9   Counting down the days to #sxsw plus strong Ca...               Apple   \n",
       "10  Excited to meet the @samsungmobileus at #sxsw ...             Android   \n",
       "\n",
       "                               emotion  \\\n",
       "0                     Negative emotion   \n",
       "1                     Positive emotion   \n",
       "2                     Positive emotion   \n",
       "3                     Negative emotion   \n",
       "4                     Positive emotion   \n",
       "5   No emotion toward brand or product   \n",
       "7                     Positive emotion   \n",
       "8                     Positive emotion   \n",
       "9                     Positive emotion   \n",
       "10                    Positive emotion   \n",
       "\n",
       "                                        cleaned_tweet  \\\n",
       "0   wesley83 i have a 3g iphone after 3 hrs tweeti...   \n",
       "1   jessedee know about fludapp  awesome ipadiphon...   \n",
       "2   swonderlin can not wait for ipad 2 also they s...   \n",
       "3   sxsw i hope this years festival isnt as crashy...   \n",
       "4   sxtxstate great stuff on fri sxsw marissa maye...   \n",
       "5   teachntech00 new ipad apps for speechtherapy a...   \n",
       "7   sxsw is just starting ctia is around the corne...   \n",
       "8   beautifully smart and simple idea rt madebyman...   \n",
       "9   counting down the days to sxsw plus strong can...   \n",
       "10  excited to meet the samsungmobileus at sxsw so...   \n",
       "\n",
       "                                     lemmatized_tweet  \n",
       "0   wesley83 i have a 3g iphone after 3 hr tweetin...  \n",
       "1   jessedee know about fludapp awesome ipadiphone...  \n",
       "2   swonderlin can not wait for ipad 2 also they s...  \n",
       "3   sxsw i hope this year festival isnt a crashy a...  \n",
       "4   sxtxstate great stuff on fri sxsw marissa maye...  \n",
       "5   teachntech00 new ipad apps for speechtherapy a...  \n",
       "7   sxsw is just starting ctia is around the corne...  \n",
       "8   beautifully smart and simple idea rt madebyman...  \n",
       "9   counting down the day to sxsw plus strong cana...  \n",
       "10  excited to meet the samsungmobileus at sxsw so...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text_nltk(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    r_stop_words = [word for word in tokens if word.lower() not in stop_words]\n",
    "  \n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to lemmatize text\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Apply the lemmatize_text function to the 'cleaned_tweet' column\n",
    "df1['lemmatized_tweet'] = df1['cleaned_tweet'].apply(lemmatize_text)\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to lemmatization,both functions play the same role ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'def preprocess_text_nltk(text)' is used to tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize and remove stopwords and punctuation\n",
    "def process_tweet(tweet):\n",
    "    tweet = tweet.lower() #convert tweet to lowercase\n",
    "   # for \n",
    "    pattern = r\"\\b\\w+(?:'\\w+)?\\b\"\n",
    "    # Create a RegexpTokenizer with the defined pattern\n",
    "    tokenizer = RegexpTokenizer(pattern)\n",
    "    # Tokenize tweet\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english') \n",
    "              and token not in punctuation]                                   \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern r\"\\b\\w+(?:'\\w+)?\\b\"  used for tokenizing text while keeping words with apostrophes. Below is an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm\", 'excited', 'about', 'the', \"iPhone's\", 'new', 'features', \"Isn't\", 'it', 'amazing']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Define the pattern\n",
    "pattern = r\"\\b\\w+(?:'\\w+)?\\b\"\n",
    "\n",
    "# Create a RegexpTokenizer with the pattern\n",
    "tokenizer = RegexpTokenizer(pattern)\n",
    "\n",
    "# Example tweet\n",
    "tweet = \"I'm excited about the iPhone's new features! Isn't it amazing?\"\n",
    "\n",
    "# Tokenize the tweet\n",
    "tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "# Print the tokens\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output shows that the tokenizer breaks dwon the tweet into components,and handling even  shortened words and ownership accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target_entity</th>\n",
       "      <th>emotion</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>lemmatized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4489</th>\n",
       "      <td>We all, including me, have this emotional thin...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>we all including me have this emotional thing ...</td>\n",
       "      <td>we all including me have this emotional thing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5438</th>\n",
       "      <td>RT @mention Apple is quarter of the music indu...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>rt mention apple is quarter of the music indus...</td>\n",
       "      <td>rt mention apple is quarter of the music indus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5350</th>\n",
       "      <td>RT @mention 20 Percent of Google Searches are ...</td>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>rt mention 20 percent of google searches are f...</td>\n",
       "      <td>rt mention 20 percent of google search are for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>CBS, SCVNGR Launch Spy Game at SXSW: If you ha...</td>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>cbs scvngr launch spy game at sxsw if you have...</td>\n",
       "      <td>cbs scvngr launch spy game at sxsw if you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7403</th>\n",
       "      <td>#SXSW -Apple Pop-Up Store being set up right n...</td>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>sxsw apple popup store being set up right now ...</td>\n",
       "      <td>sxsw apple popup store being set up right now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6544</th>\n",
       "      <td>RT @mention RT @mention Google to Launch Major...</td>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>rt mention rt mention google to launch major n...</td>\n",
       "      <td>rt mention rt mention google to launch major n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>We've got some exciting things that we'll be s...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>weve got some exciting things that well be sho...</td>\n",
       "      <td>weve got some exciting thing that well be show...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8857</th>\n",
       "      <td>I wish I was in Austin, if only for the free i...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>i wish i was in austin if only for the free ip...</td>\n",
       "      <td>i wish i wa in austin if only for the free ipa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>RT @mention OH .. #vimeo: iPhone app submitted...</td>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>rt mention oh  vimeo iphone app submitted to s...</td>\n",
       "      <td>rt mention oh vimeo iphone app submitted to st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>Very wise... RT @mention Apple is opening up a...</td>\n",
       "      <td>Other Apple product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>very wise rt mention apple is opening up a tem...</td>\n",
       "      <td>very wise rt mention apple is opening up a tem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  \\\n",
       "4489  We all, including me, have this emotional thin...   \n",
       "5438  RT @mention Apple is quarter of the music indu...   \n",
       "5350  RT @mention 20 Percent of Google Searches are ...   \n",
       "3357  CBS, SCVNGR Launch Spy Game at SXSW: If you ha...   \n",
       "7403  #SXSW -Apple Pop-Up Store being set up right n...   \n",
       "6544  RT @mention RT @mention Google to Launch Major...   \n",
       "1097  We've got some exciting things that we'll be s...   \n",
       "8857  I wish I was in Austin, if only for the free i...   \n",
       "6400  RT @mention OH .. #vimeo: iPhone app submitted...   \n",
       "1486  Very wise... RT @mention Apple is opening up a...   \n",
       "\n",
       "                       target_entity                             emotion  \\\n",
       "4489                            iPad                    Positive emotion   \n",
       "5438                           Apple                    Positive emotion   \n",
       "5350                   Uncategorized  No emotion toward brand or product   \n",
       "3357                   Uncategorized  No emotion toward brand or product   \n",
       "7403                   Uncategorized  No emotion toward brand or product   \n",
       "6544                   Uncategorized  No emotion toward brand or product   \n",
       "1097                          iPhone                    Positive emotion   \n",
       "8857                            iPad                    Positive emotion   \n",
       "6400                   Uncategorized  No emotion toward brand or product   \n",
       "1486  Other Apple product or service                    Positive emotion   \n",
       "\n",
       "                                          cleaned_tweet  \\\n",
       "4489  we all including me have this emotional thing ...   \n",
       "5438  rt mention apple is quarter of the music indus...   \n",
       "5350  rt mention 20 percent of google searches are f...   \n",
       "3357  cbs scvngr launch spy game at sxsw if you have...   \n",
       "7403  sxsw apple popup store being set up right now ...   \n",
       "6544  rt mention rt mention google to launch major n...   \n",
       "1097  weve got some exciting things that well be sho...   \n",
       "8857  i wish i was in austin if only for the free ip...   \n",
       "6400  rt mention oh  vimeo iphone app submitted to s...   \n",
       "1486  very wise rt mention apple is opening up a tem...   \n",
       "\n",
       "                                       lemmatized_tweet  \n",
       "4489  we all including me have this emotional thing ...  \n",
       "5438  rt mention apple is quarter of the music indus...  \n",
       "5350  rt mention 20 percent of google search are for...  \n",
       "3357  cbs scvngr launch spy game at sxsw if you have...  \n",
       "7403  sxsw apple popup store being set up right now ...  \n",
       "6544  rt mention rt mention google to launch major n...  \n",
       "1097  weve got some exciting thing that well be show...  \n",
       "8857  i wish i wa in austin if only for the free ipa...  \n",
       "6400  rt mention oh vimeo iphone app submitted to st...  \n",
       "1486  very wise rt mention apple is opening up a tem...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to other outputs this one right here differs from the rest becuase here we used sample and the samples of the rows we printed might containtweets with varying characteristicss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['target_entity'].fillna('Uncategorized', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
